import pandas as pd
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime, timedelta
import numpy as np
import os
from io import StringIO
import base64

# Verificar depend√™ncias opcionais
optional_deps_available = {}

try:
    import seaborn as sns
    optional_deps_available['seaborn'] = True
except ImportError:
    optional_deps_available['seaborn'] = False

try:
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler
    optional_deps_available['scikit-learn'] = True
except ImportError:
    optional_deps_available['scikit-learn'] = False

try:
    from statsmodels.tsa.seasonal import seasonal_decompose
    optional_deps_available['statsmodels'] = True
except ImportError:
    optional_deps_available['statsmodels'] = False

try:
    import networkx as nx
    optional_deps_available['networkx'] = True
except ImportError:
    optional_deps_available['networkx'] = False

try:
    from wordcloud import WordCloud
    optional_deps_available['wordcloud'] = True
except ImportError:
    optional_deps_available['wordcloud'] = False

# Configura√ß√£o da p√°gina e cache
st.set_page_config(
    page_title="Analytics Insights Dashboard",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Aplicar cache para melhorar o desempenho
@st.cache_data(ttl=3600)
def load_cached_data(file_content):
    return pd.read_csv(StringIO(file_content))

# Estilo CSS personalizado atualizado para compatibilidade com tema escuro
st.markdown("""
<style>
    /* Estilos gerais adapt√°veis ao tema */
    .main {
        background-color: transparent;
    }
    .block-container {
        padding: 2rem 3rem;
    }
    
    /* Cart√µes e destaques com cores adapt√°veis */
    .highlight {
        background-color: rgba(100, 150, 250, 0.1);
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        border: 1px solid rgba(100, 150, 250, 0.2);
    }
    .highlight-success {
        background-color: rgba(70, 200, 120, 0.1);
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        border: 1px solid rgba(70, 200, 120, 0.2);
    }
    .highlight-warning {
        background-color: rgba(250, 180, 70, 0.1);
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        border: 1px solid rgba(250, 180, 70, 0.2);
    }
    .highlight-metrics {
        background-color: rgba(120, 120, 250, 0.1);
        padding: 1rem;
        border-radius: 0.5rem;
        margin-bottom: 1rem;
        display: flex;
        justify-content: space-between;
        flex-wrap: wrap;
        border: 1px solid rgba(120, 120, 250, 0.2);
    }
    
    /* Cart√µes de m√©tricas */
    .metric-card {
        background-color: rgba(30, 30, 30, 0.2);
        padding: 1rem;
        border-radius: 0.5rem;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.2);
        text-align: center;
        width: 24%;
        margin-bottom: 0.5rem;
        border: 1px solid rgba(120, 120, 250, 0.2);
    }
    .metric-value {
        font-size: 1.8rem;
        font-weight: bold;
        margin: 0.5rem 0;
    }
    .metric-title {
        font-size: 0.9rem;
        opacity: 0.8;
    }
    
    /* Estilos para status de login */
    .logged-in {
        background-color: rgba(70, 200, 120, 0.1);
        border: 1px solid rgba(70, 200, 120, 0.2);
    }
    .not-logged-in {
        background-color: rgba(120, 120, 120, 0.1);
        border: 1px solid rgba(120, 120, 120, 0.2);
    }
    
    /* Estilos de tabs */
    .stTabs [data-baseweb="tab-list"] {
        gap: 24px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        background-color: rgba(120, 120, 120, 0.1);
        border-radius: 4px 4px 0 0;
        gap: 1px;
        padding: 0px 16px;
        font-size: 16px;
    }
    .stTabs [aria-selected="true"] {
        background-color: #4CAF50 !important;
        color: white !important;
    }
    
    /* Bot√£o de download */
    .download-button {
        display: inline-block;
        padding: 0.5rem 1rem;
        background-color: #4CAF50;
        color: white !important;
        text-decoration: none;
        border-radius: 4px;
        margin-top: 0.5rem;
        text-align: center;
    }
    .download-button:hover {
        background-color: #45a049;
    }
    
    /* Tabelas e data frames */
    .dataframe {
        border-collapse: collapse;
    }
    .dataframe th {
        background-color: rgba(120, 120, 120, 0.1);
    }
    .dataframe td, .dataframe th {
        border: 1px solid rgba(120, 120, 120, 0.2);
        padding: 8px;
    }
    
    /* Cards informativos */
    .info-card {
        background-color: rgba(70, 130, 180, 0.1);
        border-radius: 8px;
        padding: 20px;
        margin-bottom: 20px;
        border: 1px solid rgba(70, 130, 180, 0.2);
    }
    
    .info-card-title {
        font-size: 1.2rem;
        font-weight: 600;
        margin-bottom: 10px;
    }
    
    .feature-grid {
        display: grid;
        grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
        gap: 20px;
        margin: 20px 0;
    }
    
    .feature-card-one {
    background-color: rgba(100, 200, 150, 0.1); /* Tom verde-√°gua suave */
    border-radius: 8px;
    padding: 20px;
    border: 1px solid rgba(100, 200, 150, 0.2);
    transition: transform 0.3s ease;
    }

    .feature-card-one:hover {
        transform: translateY(-5px);
    }

    .feature-card-two {
        background-color: rgba(200, 150, 100, 0.1); /* Tom laranja-terroso suave */
        border-radius: 8px;
        padding: 20px;
        border: 1px solid rgba(200, 150, 100, 0.2);
        transition: transform 0.3s ease;
    }

    .feature-card-two:hover {
        transform: translateY(-5px);
    }

    .feature-card-three {
        background-color: rgba(150, 100, 200, 0.1); /* Tom roxo suave */
        border-radius: 8px;
        padding: 20px;
        border: 1px solid rgba(150, 100, 200, 0.2);
        transition: transform 0.3s ease;
    }

    .feature-card-three:hover {
        transform: translateY(-5px);
    }
    
    .feature-title {
        font-size: 1.1rem;
        font-weight: 600;
        margin-bottom: 10px;
    }
    
    /* Ajustar texto para temas escuros */
    h1, h2, h3, h4, h5, p, li, td, th, div {
        color: inherit;
    }
    
    /* Responsividade para mobile */
    @media (max-width: 768px) {
        .metric-card {
            width: 48%;
        }
        .highlight-metrics {
            flex-wrap: wrap;
        }
        .feature-grid {
            grid-template-columns: 1fr;
        }
    }
</style>
""", unsafe_allow_html=True)

# Fun√ß√£o para converter timestamp para formato leg√≠vel
def format_timestamp(timestamp):
    return datetime.fromtimestamp(int(timestamp)/1000000).strftime('%d/%m/%Y %H:%M:%S')

# Fun√ß√£o para extrair apenas a data do timestamp
def extract_date(timestamp):
    return datetime.fromtimestamp(int(timestamp)/1000000).date()

# Fun√ß√£o para extrair hora do dia
def extract_hour(timestamp):
    return datetime.fromtimestamp(int(timestamp)/1000000).hour

# Fun√ß√£o para calcular dia da semana
def extract_weekday(timestamp):
    return datetime.fromtimestamp(int(timestamp)/1000000).strftime('%A')

# Fun√ß√£o para carregar os dados
def load_data(file_path=None, uploaded_file=None):
    try:
        if uploaded_file is not None:
            # Ler conte√∫do do arquivo e usar cache
            file_content = uploaded_file.getvalue().decode('utf-8')
            df = load_cached_data(file_content)
        elif file_path is not None and os.path.exists(file_path):
            with open(file_path, 'r') as f:
                file_content = f.read()
            df = load_cached_data(file_content)
        else:
            st.error("Arquivo n√£o encontrado. Por favor, verifique o caminho ou fa√ßa upload do arquivo.")
            return None
        
        # Validar se o arquivo tem o formato esperado
        colunas_esperadas = ['event_name', 'user_id', 'client_id', 'session_number', 'session_id', 
                            'session_campaign_id', 'session_campaign_name', 'session_source', 
                            'session_medium', 'event_timestamp']
        colunas_ausentes = [col for col in colunas_esperadas if col not in df.columns]
        
        if colunas_ausentes:
            st.error(f"O arquivo CSV n√£o cont√©m todas as colunas necess√°rias. Faltam: {', '.join(colunas_ausentes)}")
            st.warning("Por favor, verifique se voc√™ est√° usando a query SQL correta para exportar os dados do GA4 conforme instru√ß√µes na p√°gina inicial.")
            return None
        
        # Converter as colunas para os tipos corretos
        df['session_number'] = df['session_number'].astype(int)
        df['event_timestamp'] = df['event_timestamp'].astype(float)
        
        # Adicionar coluna para identificar se o usu√°rio est√° logado
        df['is_logged_in'] = df['user_id'].notna()
        
        # Adicionar coluna com timestamp formatado e data
        df['formatted_timestamp'] = df['event_timestamp'].apply(format_timestamp)
        df['date'] = df['event_timestamp'].apply(extract_date)
        df['hour'] = df['event_timestamp'].apply(extract_hour)
        df['weekday'] = df['event_timestamp'].apply(extract_weekday)
        
        # Adicionar coluna para tempo desde primeiro evento (para an√°lise de funil)
        df['time_since_first_event'] = df.groupby(['client_id', 'session_number'])['event_timestamp'].transform(
            lambda x: (x - x.min()) / 1000000  # Converter para segundos
        )
        
        return df
    except Exception as e:
        st.error(f"Erro ao carregar os dados: {str(e)}")
        return None

# Fun√ß√£o para exportar dados como CSV
def get_csv_download_link(df, filename="dados_exportados.csv", button_text="Baixar dados como CSV"):
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}" class="download-button">{button_text}</a>'
    return href

# Fun√ß√£o para highlight login (compat√≠vel com tema escuro)
def highlight_login(row):
    if row.get('Usu√°rio Logado', False):
        return ['background-color: rgba(70, 200, 120, 0.1)'] * len(row)
    else:
        return ['background-color: rgba(120, 120, 120, 0.1)'] * len(row)

# Fun√ß√£o para criar um funil de eventos
def create_funnel_chart(df, event_sequence, title="Funil de Convers√£o"):
    # Contar quantos usu√°rios realizaram cada evento
    event_counts = {}
    remaining_users = set(df['client_id'].unique())
    
    for event in event_sequence:
        users_with_event = set(df[df['event_name'] == event]['client_id'].unique())
        users_in_funnel = remaining_users.intersection(users_with_event)
        event_counts[event] = len(users_in_funnel)
        remaining_users = users_in_funnel
    
    # Criar dataframe para o gr√°fico
    funnel_df = pd.DataFrame({
        'Evento': list(event_counts.keys()),
        'Usu√°rios': list(event_counts.values())
    })
    
    # Adicionar taxa de convers√£o
    funnel_df['Taxa de Convers√£o'] = 100.0
    for i in range(1, len(funnel_df)):
        prev_users = funnel_df.iloc[i-1]['Usu√°rios']
        curr_users = funnel_df.iloc[i]['Usu√°rios']
        funnel_df.loc[i, 'Taxa de Convers√£o'] = round((curr_users / prev_users * 100 if prev_users > 0 else 0), 1)
    
    # Criar gr√°fico
    fig = go.Figure(go.Funnel(
        y=funnel_df['Evento'],
        x=funnel_df['Usu√°rios'],
        textposition="inside",
        textinfo="value+percent initial",
        texttemplate="%{value} (%{percentInitial:.1%})",
        marker=dict(color=px.colors.sequential.Blues)
    ))
    
    fig.update_layout(
        title=title,
        height=400
    )
    
    return fig, funnel_df

# Fun√ß√£o para calcular m√©tricas de sess√£o
def calculate_session_metrics(df):
    # Agrupar por sess√£o e calcular m√©tricas
    session_metrics = df.groupby(['client_id', 'session_number']).agg({
        'event_timestamp': ['min', 'max', 'count'],
        'is_logged_in': 'any'
    }).reset_index()
    
    # Renomear colunas
    session_metrics.columns = ['client_id', 'session_number', 'start_time', 'end_time', 'events_count', 'is_logged_in']
    
    # Calcular dura√ß√£o da sess√£o em segundos
    session_metrics['duration_seconds'] = (session_metrics['end_time'] - session_metrics['start_time']) / 1000000
    
    return session_metrics

# P√°gina inicial com explica√ß√£o da ferramenta
def show_home_page():
    st.title("üîç Analytics Insights Dashboard")
    
    
    
    # Verificar depend√™ncias e mostrar instru√ß√µes se necess√°rio
    missing_deps = [dep for dep, available in optional_deps_available.items() if not available]
    if missing_deps:
        st.warning("### ‚ö†Ô∏è Algumas funcionalidades avan√ßadas n√£o est√£o dispon√≠veis")
        st.markdown(f"""
        Para habilitar todas as funcionalidades do dashboard, por favor instale as seguintes bibliotecas:
        
        ```
        pip install {' '.join(missing_deps)}
        ```
        
        Depois de instalar, reinicie o aplicativo para acessar os recursos avan√ßados.
        """)
    
    st.markdown("""
    <div class="info-card">
        <div class="info-card-title">Bem-vindo ao Analytics Insights Dashboard</div>
        <p>Esta ferramenta foi projetada para transformar seus dados brutos do Google Analytics 4 (GA4) em insights acion√°veis que impulsionam decis√µes estrat√©gicas.</p>
        <p>Seja voc√™ um analista de marketing, gerente de produto ou executivo, nosso dashboard oferece visualiza√ß√µes intuitivas e an√°lises profundas que revelam padr√µes ocultos no comportamento do usu√°rio.</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("### üåü Principais Funcionalidades")
    
    st.markdown("""
    <div class="feature-grid">
        <div class="feature-card-one">
            <div class="feature-title">üë§ An√°lise por Usu√°rio</div>
            <p>Examine o comportamento individual de usu√°rios ao longo do tempo, identificando padr√µes de engajamento e oportunidades de personaliza√ß√£o.</p>
            <p><strong>Benef√≠cios:</strong> Compreens√£o profunda das jornadas individuais e identifica√ß√£o de usu√°rios de alto valor.</p>
        </div>
         <div class="feature-card-two">
            <div class="feature-title">üìä An√°lise de Eventos</div>
            <p>Avalie como diferentes eventos de intera√ß√£o se comportam ao longo das sess√µes dos usu√°rios, segmentando por tipo, temporalidade e origem do tr√°fego, com an√°lises detalhadas de funil, distribui√ß√£o hor√°ria e correla√ß√µes entre eventos-chave.</p>
            <p><strong>Benef√≠cios:</strong> Otimiza√ß√£o de convers√µes por segmento, identifica√ß√£o de pontos de atrito no fluxo de usu√°rio e descoberta de padr√µes sazonais que impactam o comportamento dos visitantes.</p>
        </div>
        <div class="feature-card-three">
            <div class="feature-title">üìà Jornada do Usu√°rio</div>
            <p>Analise as intera√ß√µes dos usu√°rios atrav√©s de m√∫ltiplas perspectivas: caminhos de navega√ß√£o frequentes, tempos de convers√£o entre eventos, funis personalizados e visualiza√ß√£o de fluxos com an√°lise de drop-off.</p>
            <p><strong>Benef√≠cios:</strong> Identifica√ß√£o de gargalos de convers√£o, otimiza√ß√£o dos caminhos de navega√ß√£o, e compreens√£o detalhada do comportamento do usu√°rio em cada etapa da jornada.</p>
        </div>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("### üöÄ Como usar este dashboard")
    
    st.markdown("""
    <ol>
        <li><strong>Carregar dados:</strong> Comece fazendo upload do seu arquivo CSV de dados do GA4 ou especificando o caminho do arquivo no painel lateral.</li>
        <li><strong>Selecionar per√≠odo:</strong> Use o filtro de data para focar em per√≠odos espec√≠ficos de interesse.</li>
        <li><strong>Explorar m√≥dulos:</strong> Navegue pelas diferentes p√°ginas de an√°lise usando o menu lateral para obter insights espec√≠ficos.</li>
        <li><strong>Exportar resultados:</strong> Cada m√≥dulo oferece op√ß√µes para exportar dados e visualiza√ß√µes para relat√≥rios externos.</li>
    </ol>
    """, unsafe_allow_html=True)
    
    st.markdown("### üìä Por que usar an√°lise avan√ßada de GA4?")
    
    st.markdown("""
    <div class="info-card">
        <p>Os dados do GA4 cont√™m informa√ß√µes valiosas que muitas vezes permanecem inexploradas nas interfaces padr√£o. Nossa ferramenta desbloqueia este valor atrav√©s de:</p>
        <ul>
            <li><strong>An√°lise multi-sess√£o:</strong> Compreenda como os usu√°rios se comportam ao longo de m√∫ltiplas visitas, n√£o apenas em sess√µes isoladas.</li>
            <li><strong>Visualiza√ß√£o de canais:</strong> Avalie como diferentes fontes de tr√°fego contribuem para suas convers√µes ao longo do tempo.</li>
            <li><strong>Insights acion√°veis:</strong> Transforme dados brutos em estrat√©gias concretas para otimiza√ß√£o de produtos e marketing.</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

    # Informa√ß√µes sobre o formato CSV esperado
    st.markdown("""
    <div class="info-card">
        <div class="info-card-title">Sobre o formato de dados esperado</div>
        <p>Este dashboard foi projetado para analisar dados do Google Analytics 4 (GA4) exportados do BigQuery.</p>
        <p>O CSV esperado √© da tabela <code>events_</code> do BigQuery, que √© criada ap√≥s a vincula√ß√£o do GA4 com o BigQuery.</p>
        <p>Para extrair os dados corretamente, utilize a seguinte query SQL no BigQuery:</p>
    </div>
    """, unsafe_allow_html=True)
    
    st.code("""
        SELECT
        event_name,
        user_id,
        user_pseudo_id AS client_id,
        (
            SELECT ep.value.int_value
            FROM UNNEST(event_params) AS ep
            WHERE ep.key = 'ga_session_number'
        ) AS session_number,
        (
            SELECT ep.value.int_value
            FROM UNNEST(event_params) AS ep
            WHERE ep.key = 'ga_session_id'
        ) AS session_id,

        session_traffic_source_last_click.manual_campaign.campaign_id   AS session_campaign_id,
        session_traffic_source_last_click.manual_campaign.campaign_name AS session_campaign_name,
        session_traffic_source_last_click.manual_campaign.source         AS session_source,
        session_traffic_source_last_click.manual_campaign.medium         AS session_medium,
        session_traffic_source_last_click.manual_campaign.term           AS session_term,
        session_traffic_source_last_click.manual_campaign.content        AS session_content,
        event_timestamp
        FROM `ID da tabela`
        ORDER BY event_timestamp ASC
        """, language="sql")
    
    st.markdown("### üîß Comece agora")
    st.markdown("Carregue seus dados usando o painel lateral para descobrir insights que podem transformar sua estrat√©gia digital.")

# P√°gina de an√°lise por usu√°rio
def show_user_analysis_page(filtered_df):
    st.header("üë§ An√°lise por Usu√°rio")
    
    # Op√ß√µes de busca com duas op√ß√µes
    search_option = st.radio(
        "Buscar por:",
        ["Client ID", "User ID"]
    )
    
    # Campo de busca adapt√°vel ao tipo selecionado
    if search_option == "Client ID":
        client_id_input = st.text_input("Digite o Client ID:")
        if client_id_input:
            # Converter client_ids para string para garantir compara√ß√£o consistente
            client_ids_list = [str(cid).strip() for cid in filtered_df['client_id'].unique()]
            client_id_input = str(client_id_input).strip()
            
            if client_id_input in client_ids_list:
                # Encontrar o client_id original no dataframe que corresponde ao input
                for cid in filtered_df['client_id'].unique():
                    if str(cid).strip() == client_id_input:
                        selected_id = cid
                        search_column = 'client_id'
                        break
            else:
                st.error(f"Client ID '{client_id_input}' n√£o encontrado nos dados.")
                st.info("Tente selecionar da lista abaixo para ver os IDs dispon√≠veis.")
                selected_id = None
        else:
            # Op√ß√£o de selecionar da lista
            client_ids = filtered_df['client_id'].unique()
            selected_id = st.selectbox("Ou selecione um Client ID:", client_ids)
            search_column = 'client_id'
    
    else:  # User ID
        user_id_input = st.text_input("Digite o User ID:")
        if user_id_input:
            user_data = filtered_df[filtered_df['user_id'] == user_id_input]
            if not user_data.empty:
                # Verificar se esse user_id est√° associado a mais de um client_id
                client_ids_for_user = user_data['client_id'].unique()
                if len(client_ids_for_user) > 1:
                    st.warning(f"Este User ID est√° associado a {len(client_ids_for_user)} Client IDs diferentes!")
                    st.write("Client IDs associados:")
                    for cid in client_ids_for_user:
                        st.write(f"- {cid}")
                    selected_id = st.selectbox("Selecione um Client ID para an√°lise:", client_ids_for_user)
                else:
                    selected_id = client_ids_for_user[0]
                    search_column = 'client_id'
            else:
                st.error(f"User ID '{user_id_input}' n√£o encontrado nos dados.")
                selected_id = None
        else:
            # Op√ß√£o de selecionar da lista de user_ids n√£o vazios
            valid_user_ids = filtered_df[filtered_df['user_id'].notna()]['user_id'].unique()
            if len(valid_user_ids) > 0:
                selected_user_id = st.selectbox("Selecione um User ID:", valid_user_ids)
                user_data = filtered_df[filtered_df['user_id'] == selected_user_id]
                # Verificar se esse user_id est√° associado a mais de um client_id
                client_ids_for_user = user_data['client_id'].unique()
                if len(client_ids_for_user) > 1:
                    st.warning(f"Este User ID est√° associado a {len(client_ids_for_user)} Client IDs diferentes!")
                    st.write("Client IDs associados:")
                    for cid in client_ids_for_user:
                        st.write(f"- {cid}")
                    selected_id = st.selectbox("Selecione um Client ID para an√°lise:", client_ids_for_user)
                else:
                    selected_id = client_ids_for_user[0]
                    search_column = 'client_id'
            else:
                st.warning("N√£o foram encontrados User IDs nos dados.")
                selected_id = None
    
    # Verificar se um client_id foi selecionado/encontrado
    if selected_id and search_column == 'client_id':
        # Verificar se este client_id tem m√∫ltiplos user_ids
        user_data = filtered_df[filtered_df['client_id'] == selected_id]
        user_ids = user_data[user_data['user_id'].notna()]['user_id'].unique()
        
        if len(user_ids) > 1:
            st.warning(f"Este Client ID ('{selected_id}') est√° associado a {len(user_ids)} User IDs diferentes!")
            st.write("User IDs associados:")
            for uid in user_ids:
                st.write(f"- {uid}")
        
        # Exibir resumo das sess√µes do usu√°rio
        st.subheader(f"Sess√µes do cliente {selected_id}")
        
        # M√©tricas resumidas do usu√°rio
        total_sessions = user_data['session_number'].nunique()
        total_events = len(user_data)
        first_seen = user_data['date'].min()
        last_seen = user_data['date'].max()
        days_active = (last_seen - first_seen).days + 1
        
        # Exibir m√©tricas em cards (removida anima√ß√£o)
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.write(f"**Total de Sess√µes**\n\n{total_sessions}")
        with col2:
            st.write(f"**Total de Eventos**\n\n{total_events}")
        with col3:
            st.write(f"**Primeira Visita**\n\n{first_seen.strftime('%d/%m/%Y')}")
        with col4:
            st.write(f"**√öltima Visita**\n\n{last_seen.strftime('%d/%m/%Y')}")
        
        # Agrupar as informa√ß√µes das sess√µes
        sessions = user_data.groupby('session_number').agg({
            'session_id': 'first',
            'session_source': 'first',
            'session_medium': 'first',
            'event_timestamp': ['min', 'max'],
            'is_logged_in': 'any',
            'user_id': lambda x: x.dropna().iloc[0] if not x.dropna().empty else None
        }).reset_index()
        
        # Reorganizar colunas
        sessions.columns = ['session_number', 'session_id', 'session_source', 'session_medium', 
                            'start_timestamp', 'end_timestamp', 'is_logged_in', 'user_id']
        
        sessions['in√≠cio'] = sessions['start_timestamp'].apply(format_timestamp)
        sessions['fim'] = sessions['end_timestamp'].apply(format_timestamp)
        sessions['dura√ß√£o'] = (sessions['end_timestamp'] - sessions['start_timestamp']) / 1000000  # Em segundos
        
        # Criar dataframe de resumo de sess√£o
        session_summary = pd.DataFrame({
            'N¬∫ da Sess√£o': sessions['session_number'],
            'ID da Sess√£o': sessions['session_id'],
            'Origem': sessions['session_source'],
            'M√≠dia': sessions['session_medium'],
            'In√≠cio': sessions['in√≠cio'],
            'Dura√ß√£o (s)': sessions['dura√ß√£o'].round(1),
            'User ID': sessions['user_id'],
            'Usu√°rio Logado': sessions['is_logged_in']
        })
        
        # Contar eventos por sess√£o
        events_per_session = user_data.groupby('session_number').size().reset_index(name='num_events')
        session_summary = pd.merge(session_summary, events_per_session, 
                                  left_on='N¬∫ da Sess√£o', right_on='session_number')
        session_summary.rename(columns={'num_events': 'N¬∫ de Eventos'}, inplace=True)
        session_summary.drop(columns=['session_number'], inplace=True, errors='ignore')
        
        # Criar gr√°fico mostrando as sess√µes ao longo do tempo
        fig = px.scatter(sessions, 
                        x=sessions['in√≠cio'],  # Use a coluna j√° formatada
                        y='session_number', 
                        size='dura√ß√£o', 
                        color='is_logged_in',
                        color_discrete_map={True: '#4CAF50', False: '#9E9E9E'},
                        labels={'x': 'Data e Hora', 
                                'session_number': 'N√∫mero da Sess√£o',
                                'dura√ß√£o': 'Dura√ß√£o (s)',
                                'is_logged_in': 'Usu√°rio Logado'},
                        hover_data={
                            'in√≠cio': True,
                            'dura√ß√£o': True,
                            'session_source': True,
                            'session_medium': True
                        },
                        title="Hist√≥rico de Sess√µes do Usu√°rio")
        
        fig.update_layout(height=250)
        st.plotly_chart(fig, use_container_width=True)
        
        # Exibir tabela clic√°vel para selecionar sess√£o
        st.write("Clique em uma linha para ver os eventos dessa sess√£o:")
        st.dataframe(
            session_summary.style.apply(highlight_login, axis=1),
            use_container_width=True
        )
        
        # Selecionar sess√£o com dropdown
        session_numbers = user_data['session_number'].unique()
        # Adicionar op√ß√£o para todas as sess√µes
        session_options = ["Todas as sess√µes"] + list(session_numbers)
        
        selection = st.selectbox(
            "Selecione uma sess√£o para ver os eventos:",
            session_options
        )
        
        if selection != "Todas as sess√µes":
            # Filtrar eventos da sess√£o selecionada
            session_events = user_data[user_data['session_number'] == selection].sort_values('event_timestamp')
            
            # Verificar se h√° um user_id nesta sess√£o
            user_id_in_session = session_events[session_events['user_id'].notna()]['user_id'].unique()
            user_id_display = user_id_in_session[0] if len(user_id_in_session) > 0 else "N√£o logado"
            
            st.subheader(f"Eventos da Sess√£o {selection}")
            st.markdown(f"""
            <div class='highlight-{'success' if session_events['is_logged_in'].any() else 'warning'}'>
                <p><b>Status:</b> {'Usu√°rio logado' if session_events['is_logged_in'].any() else 'Usu√°rio n√£o logado'} |
                <b>User ID:</b> {user_id_display} |
                <b>Origem:</b> {session_events['session_source'].iloc[0]} |
                <b>M√≠dia:</b> {session_events['session_medium'].iloc[0]} |
                <b>Total de Eventos:</b> {len(session_events)}</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Preparar os dados da sequ√™ncia de eventos
            events_display = pd.DataFrame({
                'Evento': session_events['event_name'],
                'Timestamp': session_events['formatted_timestamp'],
                'Tempo desde in√≠cio (s)': session_events['time_since_first_event'].round(1),
                'User ID': session_events['user_id'],
                'Usu√°rio Logado': session_events['is_logged_in']
            })
            
            # Exibir tabela de eventos
            st.dataframe(
                events_display.style.apply(highlight_login, axis=1),
                use_container_width=True
            )
            
            # Visualiza√ß√£o da sequ√™ncia de eventos
            st.subheader("Sequ√™ncia de Eventos na Sess√£o")
            
            # Criar linha do tempo de eventos
            fig = px.scatter(
                session_events,
                x='time_since_first_event',
                y='event_name',
                color='is_logged_in',
                size_max=10,
                color_discrete_map={True: '#4CAF50', False: '#9E9E9E'},
                labels={
                    'time_since_first_event': 'Tempo desde o in√≠cio (s)',
                    'event_name': 'Evento',
                    'is_logged_in': 'Usu√°rio Logado'
                }
            )

            # Adicionar linhas para conectar eventos em sequ√™ncia
            events_ordered = session_events.sort_values('time_since_first_event')
            for i in range(len(events_ordered) - 1):
                fig.add_shape(
                    type="line",
                    x0=events_ordered.iloc[i]["time_since_first_event"],
                    y0=events_ordered.iloc[i]["event_name"],
                    x1=events_ordered.iloc[i+1]["time_since_first_event"],
                    y1=events_ordered.iloc[i+1]["event_name"],
                    line=dict(color="rgba(100, 100, 100, 0.5)", width=1)
                )

            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)
            
            # Op√ß√£o para exportar eventos
            if st.button("Exportar eventos da sess√£o"):
                st.markdown(get_csv_download_link(events_display, 
                                                "eventos_sessao.csv", 
                                                "üì• Baixar eventos da sess√£o"), 
                          unsafe_allow_html=True)
        else:
            # Mostrar eventos de todas as sess√µes
            session_events = user_data.sort_values(['session_number', 'event_timestamp'])
            
            st.subheader("Eventos de Todas as Sess√µes")
            st.markdown(f"""
            <div class='highlight'>
                <p><b>Status:</b> {'Usu√°rio logado em alguma sess√£o' if session_events['is_logged_in'].any() else 'Usu√°rio n√£o logado'} |
                <b>Total de Sess√µes:</b> {len(session_numbers)} |
                <b>Total de Eventos:</b> {len(session_events)}</p>
            </div>
            """, unsafe_allow_html=True)
            
            # Usar abas para organizar as diferentes visualiza√ß√µes
            tab1, tab2, tab3 = st.tabs(["Tabela de Eventos", "Eventos por Sess√£o", "Linha do Tempo"])
            
            with tab1:
                # Preparar os dados com a sess√£o inclu√≠da
                events_display = pd.DataFrame({
                    'Sess√£o': session_events['session_number'],
                    'Evento': session_events['event_name'],
                    'Timestamp': session_events['formatted_timestamp'],
                    'Tempo desde in√≠cio (s)': session_events['time_since_first_event'].round(1),
                    'User ID': session_events['user_id'],
                    'Usu√°rio Logado': session_events['is_logged_in']
                })
                
                st.dataframe(
                    events_display.style.apply(highlight_login, axis=1),
                    use_container_width=True
                )
                
                # Op√ß√£o para exportar todos os eventos
                if st.button("Exportar todos os eventos"):
                    st.markdown(get_csv_download_link(events_display, 
                                                    "todos_eventos_usuario.csv", 
                                                    "üì• Baixar todos os eventos"), 
                              unsafe_allow_html=True)
            
            with tab2:
                # Visualiza√ß√£o da sequ√™ncia de eventos por sess√£o
                session_events_plot = session_events.copy()
                session_events_plot['session_number'] = session_events_plot['session_number'].astype(str)
                
                fig = px.scatter(
                    session_events_plot,
                    x='time_since_first_event',
                    y='event_name',
                    color='session_number',
                    size_max=10,
                    labels={
                        'time_since_first_event': 'Tempo desde o in√≠cio da sess√£o (s)',
                        'event_name': 'Evento',
                        'session_number': 'Sess√£o'
                    }
                )
                
                fig.update_layout(height=500)
                st.plotly_chart(fig, use_container_width=True)
            
            with tab3:
                # Linha do tempo cronol√≥gica
                session_events_plot['datetime'] = pd.to_datetime(session_events_plot['event_timestamp']/1000000, unit='s')
                
                fig2 = px.scatter(
                    session_events_plot,
                    x='datetime',
                    y='session_number',
                    color='event_name',
                    size_max=10,
                    labels={
                        'datetime': 'Data e Hora',
                        'session_number': 'Sess√£o',
                        'event_name': 'Evento'
                    }
                )
                
                fig2.update_layout(height=400)
                st.plotly_chart(fig2, use_container_width=True)

# P√°gina de an√°lise de eventos
def show_event_analysis_page(filtered_df):
    st.header("üìä An√°lise de Eventos")
    
    # Obter todos os eventos dispon√≠veis e suas contagens
    all_events = sorted(filtered_df['event_name'].unique())
    event_counts = filtered_df['event_name'].value_counts()
    
    # Interface principal com abas
    tab1, tab2, tab3, tab4 = st.tabs(["üìà Vis√£o Geral", "‚è∞ Distribui√ß√£o Temporal", "üîç An√°lise Detalhada", "üîÑ Eventos por Sess√£o"])
    
    with tab1:
        st.subheader("Vis√£o Geral dos Eventos")
        
        # Top eventos
        top_n = st.slider("N√∫mero de eventos para exibir:", 5, 30, 10)
        
        # Exibir gr√°fico de barras com top eventos
        top_events = event_counts.head(top_n)
        fig = px.bar(
            top_events, 
            labels={'index': 'Evento', 'value': 'Contagem'},
            title=f"Top {top_n} Eventos Mais Frequentes"
        )
        
        fig.update_layout(height=400)
        st.plotly_chart(fig, use_container_width=True)
        
        # M√©tricas resumidas
        total_events = len(filtered_df)
        unique_events = len(all_events)
        total_sessions = filtered_df['session_number'].nunique()
        total_users = filtered_df['client_id'].nunique()
        
        # Exibir m√©tricas em colunas
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("Total de Eventos", f"{total_events:,}")
        with col2:
            st.metric("Tipos de Eventos", f"{unique_events}")
        with col3:
            st.metric("Total de Sess√µes", f"{total_sessions:,}")
        with col4:
            st.metric("Usu√°rios √önicos", f"{total_users:,}")
            
        # Tabela com detalhes dos eventos
        st.subheader("Detalhes dos Eventos")
        events_df = pd.DataFrame({
            'Evento': event_counts.index,
            'Contagem': event_counts.values,
            'Porcentagem': (event_counts.values / total_events * 100).round(2)
        })
        
        st.dataframe(events_df, use_container_width=True)
        
        # Download dos dados
        st.markdown(get_csv_download_link(events_df, 
                                         "eventos_resumo.csv",
                                         "üì• Baixar resumo de eventos"), 
                    unsafe_allow_html=True)
    
    with tab2:
        st.subheader("Distribui√ß√£o Temporal dos Eventos")
        
        # Sele√ß√£o de eventos para an√°lise temporal
        selected_events = st.multiselect(
            "Selecione eventos para an√°lise temporal:",
            options=all_events,
            default=all_events[:min(5, len(all_events))],
            format_func=lambda x: f"{x} ({event_counts[x]})"
        )
        
        if selected_events:
            # Sele√ß√£o do tipo de agrega√ß√£o temporal
            time_agg = st.radio(
                "Agregar por:",
                ["Dia", "Hora do Dia", "Dia da Semana"]
            )
            
            # Preparar dados conforme agrega√ß√£o
            if time_agg == "Dia":
                # Agrupar por data e tipo de evento
                time_data = filtered_df[filtered_df['event_name'].isin(selected_events)].copy()
                events_by_date = time_data.groupby(['date', 'event_name']).size().reset_index(name='count')
                
                # Criar gr√°fico de linha por data
                fig = px.line(
                    events_by_date, 
                    x='date', 
                    y='count', 
                    color='event_name',
                    labels={'date': 'Data', 'count': 'Contagem', 'event_name': 'Evento'},
                    title="Eventos por Dia"
                )
                
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
                
            elif time_agg == "Hora do Dia":
                # Agrupar por hora do dia e tipo de evento
                time_data = filtered_df[filtered_df['event_name'].isin(selected_events)].copy()
                events_by_hour = time_data.groupby(['hour', 'event_name']).size().reset_index(name='count')
                
                # Criar gr√°fico de linha por hora
                fig = px.line(
                    events_by_hour, 
                    x='hour', 
                    y='count', 
                    color='event_name',
                    labels={'hour': 'Hora do Dia', 'count': 'Contagem', 'event_name': 'Evento'},
                    title="Eventos por Hora do Dia"
                )
                
                fig.update_xaxes(tickmode='linear', tick0=0, dtick=1)
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
                
                # Heatmap de hora do dia x evento
                pivot_hour = events_by_hour.pivot(index='event_name', columns='hour', values='count').fillna(0)
                
                fig = px.imshow(
                    pivot_hour,
                    labels=dict(x="Hora do Dia", y="Evento", color="Contagem"),
                    title="Heatmap de Eventos por Hora"
                )
                
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
                
            else:  # Dia da Semana
                # Agrupar por dia da semana e tipo de evento
                time_data = filtered_df[filtered_df['event_name'].isin(selected_events)].copy()
                events_by_weekday = time_data.groupby(['weekday', 'event_name']).size().reset_index(name='count')
                
                # Ordenar dias da semana
                weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
                events_by_weekday['weekday_idx'] = events_by_weekday['weekday'].apply(lambda x: weekday_order.index(x))
                events_by_weekday = events_by_weekday.sort_values('weekday_idx')
                
                # Criar gr√°fico de barras por dia da semana
                fig = px.bar(
                    events_by_weekday, 
                    x='weekday', 
                    y='count', 
                    color='event_name',
                    labels={'weekday': 'Dia da Semana', 'count': 'Contagem', 'event_name': 'Evento'},
                    title="Eventos por Dia da Semana",
                    category_orders={"weekday": weekday_order}
                )
                
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
                
            # Download dos dados
            st.markdown(get_csv_download_link(events_by_date if time_agg == "Dia" else 
                                             events_by_hour if time_agg == "Hora do Dia" else
                                             events_by_weekday, 
                                         f"eventos_{time_agg.lower()}.csv",
                                         f"üì• Baixar dados por {time_agg}"), 
                      unsafe_allow_html=True)
        else:
            st.warning("Selecione pelo menos um evento para an√°lise temporal.")
    
    with tab3:
        st.subheader("An√°lise Detalhada de Eventos")
        
        # Sele√ß√£o de evento para an√°lise detalhada
        event_for_analysis = st.selectbox(
            "Selecione um evento para an√°lise detalhada:",
            options=all_events,
            format_func=lambda x: f"{x} ({event_counts[x]})"
        )
        
        if event_for_analysis:
            # Filtrar dados para o evento selecionado
            event_data = filtered_df[filtered_df['event_name'] == event_for_analysis].copy()
            
            # M√©tricas espec√≠ficas do evento
            event_sessions = event_data['session_number'].nunique()
            event_users = event_data['client_id'].nunique()
            event_logged_in = event_data[event_data['is_logged_in']]['client_id'].nunique()
            event_not_logged_in = event_users - event_logged_in
            
            # Exibir m√©tricas em colunas
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Total de Ocorr√™ncias", f"{len(event_data):,}")
            with col2:
                st.metric("Sess√µes √önicas", f"{event_sessions:,}")
            with col3:
                st.metric("Usu√°rios √önicos", f"{event_users:,}")
            with col4:
                st.metric("% Usu√°rios Logados", f"{event_logged_in / event_users * 100:.1f}%" if event_users > 0 else "0%")
            
            # An√°lise por origem de tr√°fego
            st.subheader(f"Distribui√ß√£o por Origem de Tr√°fego - {event_for_analysis}")
            
            # Agrupar por origem/m√≠dia
            traffic_data = event_data.groupby(['session_source', 'session_medium']).size().reset_index(name='count')
            traffic_data['source_medium'] = traffic_data['session_source'] + ' / ' + traffic_data['session_medium']
            traffic_data = traffic_data.sort_values('count', ascending=False)
            
            # Mostrar gr√°fico top origens
            top_traffic = traffic_data.head(10)
            
            if not top_traffic.empty:
                fig = px.pie(
                    top_traffic,
                    values='count',
                    names='source_medium',
                    title="Top 10 Origens de Tr√°fego"
                )
                
                fig.update_traces(textposition='inside', textinfo='percent+label')
                fig.update_layout(height=400)
                st.plotly_chart(fig, use_container_width=True)
            
            # Correla√ß√£o com outros eventos
            st.subheader(f"Eventos Relacionados a {event_for_analysis}")
            
            # Encontrar outros eventos que ocorrem nas mesmas sess√µes
            event_sessions = set(event_data[['client_id', 'session_number']].itertuples(index=False, name=None))
            
            related_events = []
            for other_event in all_events:
                if other_event != event_for_analysis:
                    other_data = filtered_df[filtered_df['event_name'] == other_event]
                    other_sessions = set(other_data[['client_id', 'session_number']].itertuples(index=False, name=None))
                    
                    # Sess√µes que t√™m ambos os eventos
                    common_sessions = event_sessions.intersection(other_sessions)
                    
                    if common_sessions:
                        related_events.append({
                            'Evento': other_event,
                            'Sess√µes em Comum': len(common_sessions),
                            'Porcentagem': len(common_sessions) / len(event_sessions) * 100
                        })
            
            if related_events:
                # Criar DataFrame
                related_df = pd.DataFrame(related_events)
                related_df = related_df.sort_values('Sess√µes em Comum', ascending=False)
                
                # Mostrar top eventos relacionados
                top_related = related_df.head(15)
                
                fig = px.bar(
                    top_related,
                    x='Porcentagem',
                    y='Evento',
                    orientation='h',
                    labels={
                        'Porcentagem': '% de Sess√µes em Comum',
                        'Evento': 'Evento Relacionado'
                    },
                    title=f"Eventos que Ocorrem nas Mesmas Sess√µes que {event_for_analysis}"
                )
                
                fig.update_layout(height=500, yaxis={'categoryorder':'total ascending'})
                st.plotly_chart(fig, use_container_width=True)
                
                # Exportar dados
                st.markdown(get_csv_download_link(related_df, 
                                                f"eventos_relacionados_{event_for_analysis}.csv",
                                                "üì• Baixar an√°lise de eventos relacionados"), 
                          unsafe_allow_html=True)
            else:
                st.info("N√£o foram encontrados eventos relacionados.")
    
    with tab4:
        st.subheader("üîÑ An√°lise de Eventos por Sess√£o")
        
        # Sele√ß√£o de evento para an√°lise
        evento_analise = st.selectbox(
            "Selecione um evento para analisar:",
            options=all_events,
            format_func=lambda x: f"{x} ({event_counts[x]})"
        )
        
        if evento_analise:
            # Identificar em quais sess√µes este evento ocorre
            sessoes_com_evento = filtered_df[filtered_df['event_name'] == evento_analise]['session_number'].unique()
            max_sessao = int(sessoes_com_evento.max()) if len(sessoes_com_evento) > 0 else 10
            
            # Controles para sele√ß√£o de sess√£o
            col1, col2 = st.columns(2)
            
            with col1:
                # Sele√ß√£o de n√∫mero da sess√£o
                sessao_selecionada = st.slider(
                    "N√∫mero da sess√£o para an√°lise:",
                    min_value=1,
                    max_value=max_sessao,
                    value=min(4, max_sessao)
                )
            
            with col2:
                # Op√ß√£o para filtrar apenas primeiras ocorr√™ncias
                apenas_primeiro_disparo = st.checkbox(
                    "Mostrar apenas usu√°rios que dispararam este evento pela primeira vez nesta sess√£o",
                    value=False,
                    help="Se marcado, vai filtrar apenas os usu√°rios que nunca dispararam este evento em sess√µes anteriores"
                )
            
            # Obter todos os usu√°rios que dispararam o evento na sess√£o selecionada
            usuarios_com_evento_na_sessao = filtered_df[
                (filtered_df['event_name'] == evento_analise) & 
                (filtered_df['session_number'] == sessao_selecionada)
            ]['client_id'].unique()
            
            if len(usuarios_com_evento_na_sessao) > 0:
                # Se op√ß√£o de primeiro disparo estiver marcada, filtrar mais
                if apenas_primeiro_disparo:
                    # Para cada usu√°rio, verificar se ele disparou o evento em sess√µes anteriores
                    usuarios_primeiro_disparo = []
                    
                    for user_id in usuarios_com_evento_na_sessao:
                        # Obter todas as ocorr√™ncias do evento para este usu√°rio
                        ocorrencias_usuario = filtered_df[
                            (filtered_df['client_id'] == user_id) & 
                            (filtered_df['event_name'] == evento_analise)
                        ]
                        
                        # Verificar se a primeira ocorr√™ncia √© na sess√£o selecionada
                        primeira_sessao = ocorrencias_usuario['session_number'].min()
                        if primeira_sessao == sessao_selecionada:
                            usuarios_primeiro_disparo.append(user_id)
                    
                    # Atualizar a lista de usu√°rios para an√°lise
                    usuarios_para_analise = usuarios_primeiro_disparo
                    st.success(f"Encontrados {len(usuarios_para_analise)} usu√°rios que dispararam '{evento_analise}' pela primeira vez na sess√£o {sessao_selecionada}")
                else:
                    usuarios_para_analise = usuarios_com_evento_na_sessao
                    st.success(f"Encontrados {len(usuarios_para_analise)} usu√°rios que dispararam '{evento_analise}' na sess√£o {sessao_selecionada}")
                
                # Se temos usu√°rios para analisar, seguir com a an√°lise
                if len(usuarios_para_analise) > 0:
                    # Obter todas as sess√µes desses usu√°rios at√© a sess√£o selecionada
                    dados_jornada = filtered_df[
                        (filtered_df['client_id'].isin(usuarios_para_analise)) & 
                        (filtered_df['session_number'] <= sessao_selecionada)
                    ].copy()
                    
                    # Agrupar por usu√°rio e sess√£o para obter a origem/m√≠dia de cada sess√£o
                    origens_por_sessao = dados_jornada.groupby(['client_id', 'session_number']).agg({
                        'session_source': 'first',
                        'session_medium': 'first'
                    }).reset_index()
                    
                    # Concatenar origem e m√≠dia
                    origens_por_sessao['origem_midia'] = origens_por_sessao['session_source'].fillna('(none)') + '/' + origens_por_sessao['session_medium'].fillna('(none)')
                    
                    # Analisar a distribui√ß√£o de origens/m√≠dias por n√∫mero da sess√£o
                    distribuicao_origens = origens_por_sessao.groupby(['session_number', 'origem_midia']).size().reset_index(name='count')
                    
                    # Calcular percentuais por sess√£o
                    total_por_sessao = distribuicao_origens.groupby('session_number')['count'].sum().reset_index()
                    distribuicao_origens = pd.merge(distribuicao_origens, total_por_sessao, on='session_number', suffixes=('', '_total'))
                    distribuicao_origens['percentual'] = (distribuicao_origens['count'] / distribuicao_origens['count_total'] * 100).round(1)
                    
                    # Ordenar para visualiza√ß√£o
                    distribuicao_origens = distribuicao_origens.sort_values(['session_number', 'count'], ascending=[True, False])
                    
                    # Visualizar a jornada atrav√©s das sess√µes
                    st.subheader(f"Jornada de Origens/M√≠dias at√© o Evento '{evento_analise}' na Sess√£o {sessao_selecionada}")
                    
                    # Interface para escolher visualiza√ß√£o
                    formato_viz = st.radio(
                        "Formato de visualiza√ß√£o:",
                        ["Gr√°fico de Barras", "Gr√°fico de √Årea", "Tabela Detalhada"],
                        horizontal=True
                    )
                    
                    if formato_viz == "Gr√°fico de Barras":
                        # Mostrar top origens por sess√£o
                        fig = px.bar(
                            distribuicao_origens,
                            x='session_number',
                            y='percentual',
                            color='origem_midia',
                            labels={
                                'session_number': 'N√∫mero da Sess√£o',
                                'percentual': 'Porcentagem de Usu√°rios (%)',
                                'origem_midia': 'Origem/M√≠dia'
                            },
                            title=f"Distribui√ß√£o de Origens/M√≠dias por Sess√£o para Usu√°rios com '{evento_analise}' na Sess√£o {sessao_selecionada}"
                        )
                        
                        fig.update_layout(
                            xaxis=dict(tickmode='linear', dtick=1),
                            height=500,
                            legend_title_text='Origem/M√≠dia'
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                    elif formato_viz == "Gr√°fico de √Årea":
                        # Preparar dados para gr√°fico de √°rea empilhada
                        # Precisamos de um pivot
                        pivot_origens = distribuicao_origens.pivot(index='session_number', columns='origem_midia', values='percentual').fillna(0)
                        
                        # Converter para formato long para plotly
                        long_data = pivot_origens.reset_index().melt(
                            id_vars='session_number',
                            value_vars=pivot_origens.columns,
                            var_name='origem_midia',
                            value_name='percentual'
                        )
                        
                        # Ordenar por sess√£o
                        long_data = long_data.sort_values('session_number')
                        
                        # Criar gr√°fico de √°rea
                        fig = px.area(
                            long_data,
                            x='session_number',
                            y='percentual',
                            color='origem_midia',
                            labels={
                                'session_number': 'N√∫mero da Sess√£o',
                                'percentual': 'Porcentagem de Usu√°rios (%)',
                                'origem_midia': 'Origem/M√≠dia'
                            },
                            title=f"Tend√™ncia de Origens/M√≠dias por Sess√£o para Usu√°rios com '{evento_analise}' na Sess√£o {sessao_selecionada}"
                        )
                        
                        fig.update_layout(
                            xaxis=dict(tickmode='linear', dtick=1),
                            height=500,
                            legend_title_text='Origem/M√≠dia'
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                    else:  # Tabela detalhada
                        # Mostrar tabela com porcentagens
                        tabela_origens = distribuicao_origens[['session_number', 'origem_midia', 'count', 'percentual']]
                        tabela_origens.columns = ['Sess√£o', 'Origem/M√≠dia', 'Usu√°rios', 'Porcentagem (%)']
                        
                        st.dataframe(tabela_origens, use_container_width=True)
                    
                    # An√°lise das sequ√™ncias de origens mais comuns
                    st.subheader("Sequ√™ncias de Origens/M√≠dias Mais Comuns")
                    
                    # Para cada usu√°rio, mapear sua sequ√™ncia de origens
                    usuarios_sequencias = {}
                    for user_id in usuarios_para_analise:
                        # Obter sess√µes do usu√°rio em ordem
                        sessoes_usuario = origens_por_sessao[
                            origens_por_sessao['client_id'] == user_id
                        ].sort_values('session_number')
                        
                        # Criar sequ√™ncia
                        sequencia = []
                        for i in range(1, sessao_selecionada + 1):
                            sessao_atual = sessoes_usuario[sessoes_usuario['session_number'] == i]
                            if not sessao_atual.empty:
                                sequencia.append(sessao_atual['origem_midia'].iloc[0])
                            else:
                                sequencia.append("(sem dados)")
                        
                        # Guardar sequ√™ncia
                        usuarios_sequencias[user_id] = sequencia
                    
                    # Contar frequ√™ncia de cada sequ√™ncia
                    sequencias_count = {}
                    for seq in usuarios_sequencias.values():
                        seq_str = " ‚Üí ".join(seq)
                        if seq_str in sequencias_count:
                            sequencias_count[seq_str] += 1
                        else:
                            sequencias_count[seq_str] = 1
                    
                    # Converter para DataFrame
                    sequencias_df = pd.DataFrame({
                        'Sequ√™ncia': list(sequencias_count.keys()),
                        'Contagem': list(sequencias_count.values())
                    })
                    
                    # Calcular percentual
                    total_usuarios = len(usuarios_para_analise)
                    sequencias_df['Porcentagem (%)'] = (sequencias_df['Contagem'] / total_usuarios * 100).round(1)
                    
                    # Ordenar
                    sequencias_df = sequencias_df.sort_values('Contagem', ascending=False)
                    
                    # Mostrar top 10 sequ√™ncias
                    top_n_sequencias = min(10, len(sequencias_df))
                    
                    if top_n_sequencias > 0:
                        # Visualiza√ß√£o das top sequ√™ncias
                        fig = px.bar(
                            sequencias_df.head(top_n_sequencias),
                            x='Porcentagem (%)',
                            y='Sequ√™ncia',
                            orientation='h',
                            labels={
                                'Porcentagem (%)': 'Porcentagem de Usu√°rios (%)',
                                'Sequ√™ncia': 'Sequ√™ncia de Origem/M√≠dia'
                            },
                            title=f"Top {top_n_sequencias} Sequ√™ncias de Origens/M√≠dias para Usu√°rios com '{evento_analise}' na Sess√£o {sessao_selecionada}"
                        )
                        
                        fig.update_layout(height=400, yaxis={'categoryorder':'total ascending'})
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Tabela completa
                        st.subheader("Todas as Sequ√™ncias de Origens/M√≠dias")
                        st.dataframe(sequencias_df, use_container_width=True)
                        
                        # Exportar dados
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.markdown(get_csv_download_link(
                                distribuicao_origens, 
                                f"origens_para_{evento_analise}_sessao_{sessao_selecionada}.csv",
                                "üì• Baixar dados de distribui√ß√£o de origens"
                            ), unsafe_allow_html=True)
                        
                        with col2:
                            st.markdown(get_csv_download_link(
                                sequencias_df, 
                                f"sequencias_para_{evento_analise}_sessao_{sessao_selecionada}.csv",
                                "üì• Baixar dados de sequ√™ncias"
                            ), unsafe_allow_html=True)
                    else:
                        st.warning("N√£o foi poss√≠vel identificar sequ√™ncias comuns com os dados dispon√≠veis.")
                else:
                    st.warning(f"N√£o foram encontrados usu√°rios que dispararam '{evento_analise}' pela primeira vez na sess√£o {sessao_selecionada}.")
            else:
                st.warning(f"N√£o foram encontrados usu√°rios que dispararam '{evento_analise}' na sess√£o {sessao_selecionada}.")

# P√°gina de an√°lise de jornada do usu√°rio
def show_user_journey_page(filtered_df):
    st.header("üìà An√°lise de Jornada do Usu√°rio")
    
    # Verifica√ß√£o de depend√™ncias para recursos avan√ßados
    missing_deps = []
    if not optional_deps_available.get('networkx', False):
        missing_deps.append('networkx')
    if not optional_deps_available.get('wordcloud', False):
        missing_deps.append('wordcloud')
    
    if missing_deps:
        st.warning(f"‚ö†Ô∏è Algumas visualiza√ß√µes avan√ßadas est√£o desabilitadas. Para habilitar, instale: {', '.join(missing_deps)}")
    
    # Obter todos os eventos dispon√≠veis e suas contagens
    all_events = sorted(filtered_df['event_name'].unique())
    event_counts = filtered_df['event_name'].value_counts()
    
    # Filtro global de eventos para toda a p√°gina de jornada do usu√°rio
    with st.expander("üîç Filtrar eventos para an√°lise", expanded=True):
        # Identificar eventos potencialmente autom√°ticos
        auto_events = [e for e in all_events if any(keyword in e.lower() for keyword in 
                                                 ['page_view', 'session', 'scroll', 'user_engagement', 
                                                  'click', 'view_', 'scroll', 'timing', 'gtm', 'firebase', 
                                                  'first_visit', 'app_'])]
        
        # Outros eventos (potencialmente mais importantes)
        other_events = [e for e in all_events if e not in auto_events]
        
        col1, col2 = st.columns(2)
        
        with col1:
            # Op√ß√£o para selecionar todos ou nenhum evento
            select_all = st.checkbox("Selecionar todos os eventos", value=True)
            # Op√ß√£o para excluir eventos autom√°ticos
            exclude_auto = st.checkbox("Excluir eventos autom√°ticos", value=False)
        
        with col2:
            filter_by = st.radio(
                "M√©todo de filtragem:",
                ["Selecionar eventos para incluir", "Selecionar eventos para excluir"],
                index=0
            )
        
        # Lista de eventos com contagem
        event_list = [(f"{e} ({event_counts[e]})", e) for e in all_events]
        event_list.sort(key=lambda x: x[0])
        
        # Determinar sele√ß√£o padr√£o baseada nos checkboxes
        if select_all:
            default_selection = all_events
        elif exclude_auto:
            default_selection = other_events
        else:
            default_selection = []
        
        # Widget para selecionar eventos
        if filter_by == "Selecionar eventos para incluir":
            selected_events = st.multiselect(
                "Selecione os eventos para incluir na an√°lise:",
                options=all_events,
                default=default_selection,
                format_func=lambda x: f"{x} ({event_counts[x]})"
            )
            events_to_use = selected_events
        else:
            excluded_events = st.multiselect(
                "Selecione os eventos para excluir da an√°lise:",
                options=all_events,
                default=[] if select_all else auto_events,
                format_func=lambda x: f"{x} ({event_counts[x]})"
            )
            events_to_use = [e for e in all_events if e not in excluded_events]
        
        # Aplicar filtro na DataFrame
        if events_to_use:
            journey_df = filtered_df[filtered_df['event_name'].isin(events_to_use)].copy()
            st.success(f"‚úÖ Analisando {len(events_to_use)} eventos selecionados ({len(journey_df)} registros)")
        else:
            st.error("‚ö†Ô∏è Nenhum evento selecionado. Por favor, selecione pelo menos um evento para an√°lise.")
            journey_df = filtered_df.copy()  # Usar todos os eventos como fallback
    
    # Layout principal das abas - usar journey_df (filtrada) em vez de filtered_df
    tab1, tab2, tab3, tab4 = st.tabs([
        "üõ§Ô∏è Caminhos de Navega√ß√£o", 
        "‚è±Ô∏è Tempos de Convers√£o", 
        "üîç An√°lise de Funil", 
        "üîÑ Fluxo entre Eventos"
    ])
    
    with tab1:
        st.subheader("Caminhos de Navega√ß√£o Mais Frequentes")
        
        # Sele√ß√£o de n√∫mero de passos e eventos
        col1, col2 = st.columns(2)
        with col1:
            path_length = st.slider("N√∫mero de passos no caminho:", 2, 6, 3)
        with col2:
            top_paths = st.slider("Mostrar top caminhos:", 5, 30, 10)
        
        # O multiselect de exclus√£o pode ser mantido para filtros adicionais espec√≠ficos desta aba
        exclude_events = st.multiselect(
            "Excluir eventos adicionais desta an√°lise espec√≠fica (opcional):",
            options=sorted(journey_df['event_name'].unique()),
            default=[]
        )
        
        if exclude_events:
            path_df = journey_df[~journey_df['event_name'].isin(exclude_events)].copy()
        else:
            path_df = journey_df.copy()
        
        # Implementa√ß√£o para encontrar caminhos frequentes
        if not path_df.empty:
            # Agrupar por client_id e session_number e criar uma lista de eventos em ordem
            paths_by_session = path_df.sort_values(['client_id', 'session_number', 'event_timestamp'])\
                                .groupby(['client_id', 'session_number'])['event_name'].agg(list).reset_index()
            
            # Fun√ß√£o para extrair subsequ√™ncias de um caminho
            def extract_subsequences(event_list, length):
                return [tuple(event_list[i:i+length]) for i in range(len(event_list) - length + 1)]
            
            # Extrair todos os caminhos da extens√£o solicitada
            all_paths = []
            for path in paths_by_session['event_name']:
                if len(path) >= path_length:
                    all_paths.extend(extract_subsequences(path, path_length))
            
            if all_paths:
                # Contar frequ√™ncia dos caminhos
                path_counts = pd.Series(all_paths).value_counts().reset_index()
                path_counts.columns = ['Caminho', 'Frequ√™ncia']
                
                # Converter tuplas para strings mais leg√≠veis
                path_counts['Caminho'] = path_counts['Caminho'].apply(lambda x: ' ‚Üí '.join(x))
                
                # Mostrar os caminhos mais frequentes
                st.subheader(f"Top {top_paths} caminhos mais frequentes (sequ√™ncia de {path_length} eventos)")
                
                # Filtrar para top caminhos
                top_path_counts = path_counts.head(top_paths)
                
                # Criar gr√°fico
                fig = px.bar(
                    top_path_counts, 
                    x='Frequ√™ncia', 
                    y='Caminho',
                    orientation='h',
                    labels={'Frequ√™ncia': 'N√∫mero de Ocorr√™ncias', 'Caminho': 'Sequ√™ncia de Eventos'},
                    title=f"Caminhos de navega√ß√£o mais frequentes (sequ√™ncia de {path_length} eventos)"
                )
                
                fig.update_layout(height=max(400, 30*len(top_path_counts)), yaxis={'categoryorder':'total ascending'})
                st.plotly_chart(fig, use_container_width=True)
                
                # Exportar dados
                st.markdown("##### Exportar dados de caminhos")
                st.markdown(get_csv_download_link(path_counts, 
                                                f"caminhos_navegacao_{path_length}_passos.csv",
                                                "üì• Baixar dados de caminhos"), 
                         unsafe_allow_html=True)
            else:
                st.warning(f"N√£o foram encontrados caminhos com {path_length} eventos consecutivos. Tente reduzir o tamanho do caminho.")
        else:
            st.error("N√£o h√° dados suficientes para an√°lise ap√≥s aplicar os filtros.")
    
    with tab2:
        st.subheader("Tempo de Convers√£o entre Eventos")
        
        # Interface para selecionar eventos de in√≠cio e fim
        available_events = sorted(journey_df['event_name'].unique())
        
        if len(available_events) >= 2:
            col1, col2 = st.columns(2)
            
            with col1:
                start_event = st.selectbox(
                    "Evento inicial:",
                    options=available_events,
                    index=0 if available_events else None
                )
            
            with col2:
                # Filtra para n√£o permitir selecionar o mesmo evento inicial
                end_events = [e for e in available_events if e != start_event]
                end_event = st.selectbox(
                    "Evento final:",
                    options=end_events,
                    index=0 if end_events else None
                )
            
            # Op√ß√µes adicionais
            col1, col2 = st.columns(2)
            with col1:
                segment_by = st.radio(
                    "Segmentar por:",
                    ["Nenhum", "Status de Login", "Origem/M√≠dia"]
                )
            
            with col2:
                max_time = st.slider(
                    "Tempo m√°ximo para convers√£o (minutos):",
                    1, 60, 30
                )
            
            if st.button("Analisar Tempos de Convers√£o"):
                # Filtrar apenas sess√µes que t√™m ambos os eventos
                sessions_with_both = journey_df[journey_df['event_name'].isin([start_event, end_event])]\
                                     .groupby(['client_id', 'session_number'])['event_name']\
                                     .unique()\
                                     .apply(lambda x: set([start_event, end_event]).issubset(set(x)))
                
                valid_sessions = sessions_with_both[sessions_with_both].index.tolist()
                
                if valid_sessions:
                    # Dados para an√°lise
                    conversion_data = journey_df[
                        (journey_df['event_name'].isin([start_event, end_event])) & 
                        (journey_df.set_index(['client_id', 'session_number']).index.isin(valid_sessions))
                    ].copy()
                    
                    # Calcular tempo entre eventos para cada sess√£o
                    conversion_times = []
                    
                    for (client, session), group in conversion_data.groupby(['client_id', 'session_number']):
                        # Obter o primeiro evento de in√≠cio e o primeiro de fim
                        start_time = group[group['event_name'] == start_event]['event_timestamp'].min()
                        end_time = group[group['event_name'] == end_event]['event_timestamp'].min()
                        
                        # Verificar se o evento de fim ocorre ap√≥s o de in√≠cio
                        if end_time > start_time:
                            time_diff = (end_time - start_time) / 1000000  # Converter para segundos
                            
                            # Filtrar por tempo m√°ximo (converter minutos para segundos)
                            if time_diff <= (max_time * 60):
                                # Adicionar dados para segmenta√ß√£o
                                is_logged_in = group['is_logged_in'].any()
                                source = group['session_source'].iloc[0]
                                medium = group['session_medium'].iloc[0]
                                
                                conversion_times.append({
                                    'client_id': client,
                                    'session_number': session,
                                    'time_diff_seconds': time_diff,
                                    'is_logged_in': is_logged_in,
                                    'source': source,
                                    'medium': medium,
                                    'source_medium': f"{source}/{medium}" if source and medium else "N√£o definido"
                                })
                    
                    if conversion_times:
                        # Criar DataFrame com tempos
                        times_df = pd.DataFrame(conversion_times)
                        
                        # Mostrar estat√≠sticas gerais
                        avg_time = times_df['time_diff_seconds'].mean()
                        median_time = times_df['time_diff_seconds'].median()
                        min_time = times_df['time_diff_seconds'].min()
                        max_time = times_df['time_diff_seconds'].max()
                        
                        # Formata√ß√£o para exibi√ß√£o
                        fmt_time = lambda secs: f"{int(secs//60)}m {int(secs%60)}s"
                        
                        # Exibir estat√≠sticas
                        st.markdown(f"""
                        #### Estat√≠sticas de tempo entre **{start_event}** e **{end_event}**
                        
                        - **Total de convers√µes:** {len(times_df)}
                        - **Tempo m√©dio:** {fmt_time(avg_time)} ({avg_time:.1f}s)
                        - **Tempo mediano:** {fmt_time(median_time)} ({median_time:.1f}s)
                        - **Tempo m√≠nimo:** {fmt_time(min_time)} ({min_time:.1f}s)
                        - **Tempo m√°ximo:** {fmt_time(max_time)} ({max_time:.1f}s)
                        """)
                        
                        # Criar histograma de distribui√ß√£o
                        fig = px.histogram(
                            times_df, 
                            x='time_diff_seconds',
                            nbins=20,
                            labels={'time_diff_seconds': 'Tempo (segundos)'},
                            title=f"Distribui√ß√£o do tempo entre {start_event} e {end_event}"
                        )
                        
                        fig.update_layout(height=400)
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Segmenta√ß√£o por atributo selecionado
                        if segment_by == "Status de Login":
                            # Agrupar por status de login
                            login_stats = times_df.groupby('is_logged_in')['time_diff_seconds'].agg(
                                ['mean', 'median', 'min', 'max', 'count']
                            ).reset_index()
                            
                            login_stats.columns = ['Usu√°rio Logado', 'M√©dia (s)', 'Mediana (s)', 'M√≠nimo (s)', 'M√°ximo (s)', 'Contagem']
                            
                            # Formatar booleano
                            login_stats['Usu√°rio Logado'] = login_stats['Usu√°rio Logado'].map({True: 'Sim', False: 'N√£o'})
                            
                            st.subheader("Segmenta√ß√£o por Status de Login")
                            st.dataframe(login_stats)
                            
                            # Gr√°fico de compara√ß√£o
                            fig = px.box(
                                times_df,
                                x='is_logged_in',
                                y='time_diff_seconds',
                                labels={
                                    'is_logged_in': 'Usu√°rio Logado',
                                    'time_diff_seconds': 'Tempo (segundos)'
                                },
                                category_orders={'is_logged_in': [True, False]},
                                title="Compara√ß√£o de tempos por status de login"
                            )
                            
                            # Atualizar nomes das categorias
                            fig.update_xaxes(
                                ticktext=["Logado", "N√£o Logado"],
                                tickvals=[True, False]
                            )
                            
                            st.plotly_chart(fig, use_container_width=True)
                            
                        elif segment_by == "Origem/M√≠dia":
                            # Top origens/m√≠dias
                            top_sources = times_df['source_medium'].value_counts().head(10).index.tolist()
                            
                            # Filtrar para top origens
                            source_data = times_df[times_df['source_medium'].isin(top_sources)].copy()
                            
                            if not source_data.empty:
                                # Agrupar por origem/m√≠dia
                                source_stats = source_data.groupby('source_medium')['time_diff_seconds'].agg(
                                    ['mean', 'median', 'min', 'max', 'count']
                                ).reset_index()
                                
                                source_stats.columns = ['Origem/M√≠dia', 'M√©dia (s)', 'Mediana (s)', 'M√≠nimo (s)', 'M√°ximo (s)', 'Contagem']
                                
                                # Ordenar por contagem
                                source_stats = source_stats.sort_values('Contagem', ascending=False)
                                
                                st.subheader("Segmenta√ß√£o por Origem/M√≠dia (Top 10)")
                                st.dataframe(source_stats)
                                
                                # Gr√°fico de compara√ß√£o
                                if len(source_data) >= 5:  # S√≥ mostrar se tiver dados suficientes
                                    fig = px.box(
                                        source_data,
                                        x='source_medium',
                                        y='time_diff_seconds',
                                        labels={
                                            'source_medium': 'Origem/M√≠dia',
                                            'time_diff_seconds': 'Tempo (segundos)'
                                        },
                                        title="Compara√ß√£o de tempos por origem/m√≠dia"
                                    )
                                    
                                    fig.update_layout(height=400)
                                    st.plotly_chart(fig, use_container_width=True)
                            else:
                                st.warning("Dados insuficientes para segmenta√ß√£o por origem/m√≠dia.")
                        
                        # Exportar dados
                        st.markdown("##### Exportar dados de convers√£o")
                        st.markdown(get_csv_download_link(times_df, 
                                                    f"tempos_conversao_{start_event}_to_{end_event}.csv",
                                                    "üì• Baixar dados de tempos"), 
                                 unsafe_allow_html=True)
                    else:
                        st.warning(f"N√£o foram encontradas convers√µes de {start_event} para {end_event} dentro do limite de tempo de {max_time} minutos.")
                else:
                    st.warning(f"N√£o foram encontradas sess√µes que contenham ambos eventos: {start_event} e {end_event}.")
        else:
            st.error("N√£o h√° eventos suficientes para an√°lise. Selecione pelo menos dois eventos diferentes.")
    
    with tab3:
        st.subheader("An√°lise de Funil")
        
        # Interface para criar um funil personalizado
        st.markdown("Defina uma sequ√™ncia de eventos para analisar como funil de convers√£o.")
        
        # Lista de eventos dispon√≠veis (j√° filtrados)
        available_events = sorted(journey_df['event_name'].unique())
        
        if len(available_events) >= 2:
            # Sele√ß√£o de eventos m√∫ltiplos para o funil
            funnel_events = st.multiselect(
                "Selecione os eventos do funil (na ordem desejada):",
                options=available_events,
                default=available_events[:min(3, len(available_events))]
            )
            
            # Op√ß√µes de an√°lise
            col1, col2 = st.columns(2)
            
            with col1:
                strict_order = st.checkbox("Ordem estrita dos eventos", value=True, 
                                          help="Se marcado, os eventos devem ocorrer na ordem exata. Se desmarcado, apenas verifica se ocorreram na sess√£o.")
                
            with col2:
                session_based = st.checkbox("An√°lise por sess√£o", value=True,
                                          help="Se marcado, analisa convers√µes dentro de cada sess√£o. Se desmarcado, analisa convers√µes em todas as sess√µes do usu√°rio.")
            
            # Verificar se h√° eventos suficientes
            if len(funnel_events) >= 2:
                if st.button("Gerar Funil"):
                    # Preparar os dados conforme as op√ß√µes
                    if session_based:
                        # Analisar por sess√£o
                        groupby_cols = ['client_id', 'session_number']
                    else:
                        # Analisar por usu√°rio em todas as sess√µes
                        groupby_cols = ['client_id']
                    
                    if strict_order:
                        # Funil com ordem estrita - implementa√ß√£o j√° existe na fun√ß√£o create_funnel_chart
                        funnel_df = journey_df[journey_df['event_name'].isin(funnel_events)].copy()
                        fig, funnel_data = create_funnel_chart(funnel_df, funnel_events, 
                                                              title=f"Funil de Convers√£o - {'Sess√£o' if session_based else 'Usu√°rio'}")
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Tabela com dados detalhados
                        st.subheader("Detalhes do Funil")
                        st.dataframe(funnel_data)
                        
                    else:
                        # Vers√£o simplificada: apenas verifica se os eventos ocorreram, sem ordem
                        # Contar quantos usu√°rios/sess√µes realizaram cada evento
                        funnel_data = []
                        
                        for event in funnel_events:
                            # Filtrar para este evento
                            event_data = journey_df[journey_df['event_name'] == event]
                            
                            # Contar usu√°rios/sess√µes √∫nicos
                            unique_count = event_data.groupby(groupby_cols).size().shape[0]
                            
                            funnel_data.append({
                                'Evento': event,
                                'Usu√°rios/Sess√µes': unique_count
                            })
                        
                        # Criar DataFrame
                        funnel_df = pd.DataFrame(funnel_data)
                        
                        # Calcular taxa de convers√£o
                        max_count = funnel_df['Usu√°rios/Sess√µes'].max()
                        funnel_df['Taxa (%)'] = funnel_df['Usu√°rios/Sess√µes'] / max_count * 100
                        
                        # Criar gr√°fico de funil
                        fig = px.funnel(
                            funnel_df,
                            x='Usu√°rios/Sess√µes',
                            y='Evento',
                            title=f"Funil de Eventos - {'Sess√£o' if session_based else 'Usu√°rio'} (Sem ordem estrita)"
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Tabela com dados detalhados
                        st.subheader("Detalhes do Funil")
                        st.dataframe(funnel_df)
                    
                    # Exportar dados
                    st.markdown("##### Exportar dados do funil")
                    st.markdown(get_csv_download_link(funnel_data if strict_order else funnel_df, 
                                                  "dados_funil.csv",
                                                  "üì• Baixar dados do funil"), 
                               unsafe_allow_html=True)
                else:
                    st.warning("Selecione pelo menos 2 eventos para gerar um funil de convers√£o.")
            else:
                st.warning("N√£o h√° eventos suficientes para an√°lise. Selecione pelo menos dois eventos diferentes.")
        else:
            st.error("N√£o h√° eventos suficientes para an√°lise. Selecione pelo menos dois eventos diferentes.")
    
    with tab4:
        st.subheader("Fluxo entre Eventos")
        
        # Verificar se a biblioteca networkx est√° dispon√≠vel
        if not optional_deps_available.get('networkx', False):
            st.error("Esta funcionalidade requer a biblioteca 'networkx'. Instale-a com 'pip install networkx' e reinicie a aplica√ß√£o.")
        else:
            # Importar networkx aqui (j√° verificamos que est√° dispon√≠vel)
            import networkx as nx
            
            # Interface para configurar an√°lise
            col1, col2 = st.columns(2)
            
            with col1:
                min_occurrences = st.slider(
                    "M√≠nimo de ocorr√™ncias:",
                    1, 100, 5,
                    help="Filtrar transi√ß√µes com pelo menos este n√∫mero de ocorr√™ncias"
                )
            
            with col2:
                analysis_scope = st.radio(
                    "Escopo da an√°lise:",
                    ["Por Sess√£o", "Por Usu√°rio"],
                    index=0,
                    help="Analisar transi√ß√µes dentro da mesma sess√£o ou para o mesmo usu√°rio entre sess√µes"
                )
            
            # Executar an√°lise de fluxo
            if st.button("Analisar Fluxo de Eventos"):
                # Contar ocorr√™ncias de cada evento
                event_counts = journey_df['event_name'].value_counts()
                
                # Filtrar eventos que atendem ao m√≠nimo de ocorr√™ncias
                events_to_include = event_counts[event_counts >= min_occurrences].index.tolist()
                
                if len(events_to_include) >= 2:
                    # Filtrar DataFrame para esses eventos
                    flow_df = journey_df[journey_df['event_name'].isin(events_to_include)].copy()
                    
                    # Determinar agrupamento com base no escopo
                    if analysis_scope == "Por Sess√£o":
                        groupby_cols = ['client_id', 'session_number']
                    else:
                        groupby_cols = ['client_id']
                    
                    # Ordenar eventos por timestamp
                    flow_df = flow_df.sort_values(groupby_cols + ['event_timestamp'])
                    
                    # Criar grafo dirigido
                    G = nx.DiGraph()
                    
                    # Adicionar n√≥s para cada evento (com contagem)
                    for event, count in event_counts[events_to_include].items():
                        G.add_node(event, count=count)
                    
                    # Construir as arestas
                    edge_counts = {}
                    user_sets = {}  # Para rastrear quais usu√°rios fizeram cada transi√ß√£o
                    
                    # Iterar sobre grupos (sess√µes ou usu√°rios)
                    for group_key, group_df in flow_df.groupby(groupby_cols):
                        # Obter sequ√™ncia de eventos
                        events = group_df['event_name'].tolist()
                        client_id = group_key[0]  # O client_id sempre √© o primeiro elemento
                        
                        # Criar pares de eventos consecutivos
                        for i in range(len(events) - 1):
                            edge = (events[i], events[i+1])
                            
                            # Incrementar contagem
                            if edge in edge_counts:
                                edge_counts[edge] += 1
                                user_sets[edge].add(client_id)
                            else:
                                edge_counts[edge] = 1
                                user_sets[edge] = {client_id}
                    
                    # Adicionar arestas ao grafo
                    for (source, target), count in edge_counts.items():
                        if count >= min_occurrences:
                            G.add_edge(source, target, 
                                      weight=count, 
                                      users=user_sets[(source, target)])
                    
                    # Verificar se h√° arestas suficientes
                    if len(G.edges()) > 0:
                        # Calcular m√©tricas de centralidade
                        centrality = nx.betweenness_centrality(G, weight='weight')
                        in_degree = dict(G.in_degree(weight='weight'))
                        out_degree = dict(G.out_degree(weight='weight'))
                        
                        # Adicionar m√©tricas aos n√≥s
                        for node in G.nodes():
                            G.nodes[node]['centrality'] = centrality[node]
                            G.nodes[node]['in_degree'] = in_degree[node]
                            G.nodes[node]['out_degree'] = out_degree[node]
                        
                        # Criar diagrama de Sankey
                        sources = []
                        targets = []
                        values = []
                        labels = []
                        
                        # Coletar n√≥s √∫nicos
                        nodes = set()
                        for u, v in G.edges():
                            nodes.add(u)
                            nodes.add(v)
                        
                        # Mapear n√≥s para √≠ndices
                        node_indices = {node: i for i, node in enumerate(nodes)}
                        
                        # Preparar dados para Sankey
                        for u, v, data in G.edges(data=True):
                            sources.append(node_indices[u])
                            targets.append(node_indices[v])
                            values.append(data['weight'])
                        
                        # Lista de labels na ordem correta
                        for node in nodes:
                            labels.append(node)
                        
                        # Criar gr√°fico Sankey
                        fig = go.Figure(data=[go.Sankey(
                            node=dict(
                                pad=15,
                                thickness=20,
                                line=dict(color="black", width=0.5),
                                label=labels
                            ),
                            link=dict(
                                source=sources,
                                target=targets,
                                value=values,
                                customdata=[len(G[labels[s]][labels[t]]['users']) 
                                          for s, t in zip(sources, targets)],
                                hovertemplate='%{source.label} ‚Üí %{target.label}<br>'
                                            'Transi√ß√µes: %{value}<br>'
                                            'Usu√°rios √∫nicos: %{customdata}<extra></extra>'
                            )
                        )])
                        
                        fig.update_layout(
                            title="Fluxo entre Eventos",
                            height=600,
                            font=dict(size=10)
                        )
                        
                        st.plotly_chart(fig, use_container_width=True)
                        
                        # Eventos mais relevantes (baseado na centralidade)
                        st.subheader("Eventos Cr√≠ticos (Centralidade)")
                        centrality_df = pd.DataFrame({
                            'Evento': list(centrality.keys()),
                            'Centralidade': list(centrality.values()),
                            'Entrada': [in_degree[node] for node in centrality.keys()],
                            'Sa√≠da': [out_degree[node] for node in centrality.keys()]
                        }).sort_values('Centralidade', ascending=False)
                        
                        st.dataframe(centrality_df)
                        
                        # An√°lise de drop-off
                        st.subheader("An√°lise de Drop-off")
                        
                        # Calcular taxas de drop-off
                        dropoff_data = []
                        
                        for node in G.nodes():
                            in_flow = in_degree.get(node, 0)
                            out_flow = out_degree.get(node, 0)
                            
                            # Calcular drop-off apenas para n√≥s que t√™m entrada
                            if in_flow > 0:
                                dropoff_rate = (in_flow - out_flow) / in_flow
                                dropoff_data.append({
                                    'Evento': node,
                                    'Entrada': in_flow,
                                    'Sa√≠da': out_flow,
                                    'Taxa de Drop-off (%)': round(max(0, dropoff_rate) * 100, 1)
                                })
                        
                        # Criar DataFrame
                        dropoff_df = pd.DataFrame(dropoff_data)
                        dropoff_df = dropoff_df.sort_values('Taxa de Drop-off (%)', ascending=False)
                        
                        # Mostrar tabela
                        st.dataframe(dropoff_df)
                        
                        # Gr√°fico para top eventos com maior drop-off
                        top_dropoff = dropoff_df.head(10)
                        
                        if not top_dropoff.empty:
                            fig = px.bar(
                                top_dropoff,
                                x='Taxa de Drop-off (%)',
                                y='Evento',
                                orientation='h',
                                labels={
                                    'Taxa de Drop-off (%)': 'Taxa de Drop-off (%)',
                                    'Evento': 'Evento'
                                },
                                title="Top Eventos com Maior Taxa de Drop-off"
                            )
                            
                            fig.update_layout(height=400, yaxis={'categoryorder':'total ascending'})
                            st.plotly_chart(fig, use_container_width=True)
                        
                        # Exportar dados
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            st.markdown("##### Exportar dados de fluxo")
                            
                            # Preparar dados de arestas para exporta√ß√£o
                            edge_data = []
                            for u, v, data in G.edges(data=True):
                                edge_data.append({
                                    'Origem': u,
                                    'Destino': v,
                                    'Transi√ß√µes': data['weight'],
                                    'Usu√°rios √önicos': len(data['users'])
                                })
                            
                            edge_df = pd.DataFrame(edge_data)
                            
                            st.markdown(get_csv_download_link(edge_df, 
                                                      "fluxo_entre_eventos.csv",
                                                      "üì• Baixar dados de fluxo"), 
                                     unsafe_allow_html=True)
                        
                        with col2:
                            st.markdown("##### Exportar dados de drop-off")
                            st.markdown(get_csv_download_link(dropoff_df, 
                                                      "analise_dropoff.csv",
                                                      "üì• Baixar dados de drop-off"), 
                                     unsafe_allow_html=True)
                    else:
                        st.warning("N√£o foram encontradas transi√ß√µes suficientes para an√°lise. Tente reduzir o m√≠nimo de ocorr√™ncias.")
                else:
                    st.warning(f"N√£o h√° eventos suficientes com pelo menos {min_occurrences} ocorr√™ncias. Tente reduzir o valor m√≠nimo.")

# Fun√ß√£o principal para executar o dashboard
def main():
    # Interface para upload/sele√ß√£o do arquivo
    st.sidebar.header("üìÇ Dados")
    file_option = st.sidebar.radio("Escolha como carregar os dados:", ["Upload de arquivo"])
    
    df = None
    
    # Carregamento dos dados
    if file_option == "Upload de arquivo":
        uploaded_file = st.sidebar.file_uploader("Escolha um arquivo CSV", type="csv")
        if uploaded_file is not None:
            df = load_data(uploaded_file=uploaded_file)
    else:
        file_path = st.sidebar.text_input("Digite o caminho completo do arquivo CSV:")
        if file_path:
            df = load_data(file_path=file_path)
    
    # Verificar se os dados foram carregados
    dados_carregados = df is not None
    
    # Sele√ß√£o da p√°gina
    st.sidebar.header("üìë Navega√ß√£o")
    # Desabilitar p√°ginas de an√°lise se n√£o houver dados
    paginas_disponiveis = ["üìå In√≠cio"]
    if dados_carregados:
        paginas_disponiveis += ["üë§ An√°lise por Usu√°rio", "üìä An√°lise de Eventos", "üìà Jornada do Usu√°rio"]
    
    page = st.sidebar.selectbox(
        "Selecione uma p√°gina:",
        paginas_disponiveis
    )
    
    # P√°gina de in√≠cio (ou se n√£o tiver dados carregados)
    if page == "üìå In√≠cio" or not dados_carregados:
        show_home_page()
        if not dados_carregados:
            return
    
    # Continuar apenas se os dados forem carregados
    # Filtros de data
    st.sidebar.header("üìÖ Filtros")
    # Obter intervalo de datas
    min_date = df['date'].min()
    max_date = df['date'].max()
    date_range = st.sidebar.date_input(
        "Filtrar por per√≠odo:",
        [min_date, max_date],
        min_value=min_date,
        max_value=max_date
    )
    
    # Aplicar filtro de data se necess√°rio
    if len(date_range) == 2:
        start_date, end_date = date_range
        # Ajustar end_date para incluir todo o dia
        end_date = datetime.combine(end_date, datetime.max.time()).date()
        filtered_df = df[(df['date'] >= start_date) & (df['date'] <= end_date)]
    else:
        filtered_df = df
    
    # Mostrar quantos registros foram filtrados
    st.sidebar.info(f"Mostrando {len(filtered_df):,} de {len(df):,} eventos ({(len(filtered_df)/len(df)*100):.1f}%)")
    
    # Exibir a p√°gina selecionada
    if page == "üë§ An√°lise por Usu√°rio":
        show_user_analysis_page(filtered_df)
    elif page == "üìä An√°lise de Eventos":
        show_event_analysis_page(filtered_df)
    elif page == "üìà Jornada do Usu√°rio":
        show_user_journey_page(filtered_df)

# Executar o aplicativo
if __name__ == "__main__":
    main()